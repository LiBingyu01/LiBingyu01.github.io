<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bingyu Li (æç‚³ç…œ) - Homepage</title>
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.3/css/academicons.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">

    <style>
        /* --- 1. å…¨å±€åŸºç¡€æ ·å¼ --- */
        body {
            font-family: 'Roboto', -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            background-color: #ffffff;
            color: #333;
            margin: 0;
            line-height: 1.6;
        }

        a { text-decoration: none; color: #0077b6; }
        a:hover { text-decoration: underline; }

        /* --- 2. é¡¶éƒ¨æ°´å¹³å¯¼èˆªæ  (å¯¹åº”éœ€æ±‚2) --- */
        .navbar {
            padding: 15px 40px;
            border-bottom: 1px solid #eee;
            margin-bottom: 40px;
            background: #fff;
            position: sticky; /* é¡¶éƒ¨å¸é™„ */
            top: 0;
            z-index: 1000;
        }
        .nav-list {
            list-style: none;
            padding: 0;
            margin: 0;
            display: flex;
            gap: 30px; /* èœå•é—´è· */
            font-size: 16px;
            font-weight: 500;
            max-width: 1200px;
            margin: 0 auto;
        }
        .nav-list li a { color: #555; transition: color 0.3s; }
        .nav-list li a:hover { color: #0077b6; }

        /* --- 3. åŒæ å¸ƒå±€å®¹å™¨ (å¯¹åº”éœ€æ±‚1) --- */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex; /* Flexå¸ƒå±€å®ç°å·¦å³åˆ†æ  */
            padding: 0 20px;
            gap: 60px; /* å·¦å³æ é—´è· */
        }

        /* --- 4. å·¦ä¾§ä¾§è¾¹æ æ ·å¼ (å¯¹åº”éœ€æ±‚3) --- */
        .sidebar {
            width: 260px; /* å›ºå®šå®½åº¦ */
            flex-shrink: 0;
        }

        /* åœ†å½¢å¤´åƒå®¹å™¨ */
        .avatar-container {
            width: 200px;
            height: 200px;
            margin: 0 auto 20px auto; /* å±…ä¸­ */
            border-radius: 50%; /* å˜æˆåœ†å½¢ */
            overflow: hidden;
            border: 1px solid #eee;
            box-shadow: 0 4px 10px rgba(0,0,0,0.05);
        }
        .avatar-container img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .profile-name {
            font-size: 22px;
            font-weight: bold;
            margin-bottom: 8px;
            color: #222;
        }
        .profile-affil {
            font-size: 15px;
            color: #555;
            margin-bottom: 20px;
            line-height: 1.4;
        }
        
        /* ä¾§è¾¹æ å›¾æ ‡åˆ—è¡¨ */
        .sidebar-links {
            list-style: none;
            padding: 0;
            font-size: 14px;
            color: #444;
        }
        .sidebar-links li {
            margin-bottom: 12px;
            display: flex;
            align-items: center;
        }
        .sidebar-links i {
            width: 24px;
            color: #555;
            margin-right: 5px;
            text-align: center;
        }

        /* --- 5. å³ä¾§ä¸»å†…å®¹åŒºæ ·å¼ (å¯¹åº”éœ€æ±‚4) --- */
        .main-content {
            flex-grow: 1;
            max-width: 850px;
            padding-bottom: 50px;
        }

        /* ç« èŠ‚æ ‡é¢˜å¸¦å›¾æ ‡ */
        h1 {
            font-size: 24px;
            border-bottom: 2px solid #f0f0f0;
            padding-bottom: 10px;
            margin-bottom: 20px;
            margin-top: 40px;
            color: #222;
        }
        h1:first-child { margin-top: 0; }

        /* æ–°é—»åˆ—è¡¨ */
        .news-list {
            list-style: none;
            padding: 0;
        }
        .news-list li {
            margin-bottom: 10px;
            display: flex;
            align-items: baseline;
            font-size: 15px;
        }
        .date {
            font-family: 'Courier New', monospace;
            font-weight: bold;
            min-width: 85px;
            color: #666;
            flex-shrink: 0;
        }

        /* --- è®ºæ–‡å¡ç‰‡æ ·å¼ (Paper Box) --- */
        .paper-box {
            display: flex;
            gap: 20px;
            margin-bottom: 25px;
            padding: 15px;
            background: #fff;
            border: 1px solid #eee;
            border-radius: 8px;
            transition: box-shadow 0.3s;
        }
        .paper-box:hover {
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        }
        
        .paper-img {
            flex: 0 0 280px; /* å·¦ä¾§å›¾ç‰‡å›ºå®šå®½åº¦ */
            position: relative;
        }
        .paper-img img {
            width: 100%;
            border-radius: 4px;
            border: 1px solid #f0f0f0;
        }
        .badge {
            position: absolute;
            top: 5px;
            right: 5px;
            background: #d9534f;
            color: white;
            padding: 2px 6px;
            font-size: 11px;
            font-weight: bold;
            border-radius: 3px;
        }
        
        .paper-txt {
            flex: 1;
        }
        .paper-title {
            font-weight: bold;
            font-size: 17px;
            color: #0077b6;
            margin-bottom: 5px;
            display: block;
        }
        .paper-authors {
            color: #444;
            font-size: 15px;
            margin-bottom: 8px;
        }
        .paper-desc {
            font-size: 14px;
            color: #666;
            margin-top: 8px;
        }

        /* --- ç§»åŠ¨ç«¯å“åº”å¼ --- */
        @media (max-width: 768px) {
            .container { flex-direction: column; }
            .sidebar { width: 100%; text-align: center; margin-bottom: 30px; }
            .nav-list { flex-wrap: wrap; justify-content: center; gap: 15px; }
            .sidebar-links li { justify-content: center; }
            .paper-box { flex-direction: column; }
            .paper-img { flex: 0 0 auto; width: 100%; }
        }
    </style>
</head>

<body>

    <nav class="navbar">
        <ul class="nav-list">
            <li><a href="#">Homepage</a></li>
            <li><a href="#about">About Me</a></li>
            <li><a href="#news">News</a></li>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#honors">>Honors></li>
            <li><a href="#service">Service</a></li>
        </ul>
    </nav>

    <div class="container">
        
        <aside class="sidebar">
            <div class="avatar-container">
                <img src="images/me.png" alt="Bingyu Li" onerror="this.src='https://placehold.co/200x200?text=Bingyu'">
            </div>

            <div class="profile-name">Bingyu Li (æç‚³ç…œ)</div>
            <div class="profile-affil">
                University of Science and Technology of China
            </div>
            
            <ul class="sidebar-links">
                <li><i class="fas fa-graduation-cap"></i> Ph.D. Student, USTC</li>
                <li><i class="fas fa-map-marker-alt"></i> Hefei, China</li>
                <li><i class="fas fa-envelope"></i> <a href="mailto:libingyu0205@mail.ustc.edu.cn">Email</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/LiBingyu01">Github</a></li>
                <li><i class="ai ai-google-scholar"></i> <a href="https://scholar.google.com/citations?user=6AdA-O4AAAAJ&hl=zh-CN">Google Scholar</a></li>
            </ul>
        </aside>

        <main class="main-content">
            
            <section id="about">
                <h1>ğŸ‘‹ About Me</h1>
                <p>I am a Ph.D. student at the <a href="https://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>, supervised by Prof. Xuelong Li.</p>
                <p>My research focuses on applying multimodal large language models and vision-language models to visual tasks across diverse scenes.</p>
            </section>

            <section id="topics">
                <h1>ğŸ” Research Topics</h1>
                <ul>
                    <li><strong>Multimodal LLMs</strong>: Vision-Language Models, Foundation Models.</li>
                    <li><strong>Computer Vision</strong>: Open-Vocabulary Segmentation, Video Understanding.</li>
                    <li><strong>Domain Applications</strong>: Remote Sensing Vision, Underwater Vision.</li>
                </ul>
            </section>

            <section id="news">
                <h1>ğŸ”¥ News</h1>
                <ul class="news-list">
                    <li>
                        <span class="date">2025.11</span> 
                        <span>One paper is accepted by AAAI 2026 (<b style="color:#d9534f">Oral</b>)! ğŸ‰</span>
                    </li>
                    <li>
                        <span class="date">2025.10</span> 
                        <span>Awarded National Scholarship for Graduate Students (ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘)! ğŸ–ï¸</span>
                    </li>
                    <li>
                        <span class="date">2025.04</span> 
                        <span><a href="#">Stitchfusion</a> is accepted by ACM MM 2025 (<b style="color:#d9534f">Oral</b>).</span>
                    </li>
                    <li>
                        <span class="date">2024.09</span> 
                        <span>Started Ph.D. journey at USTC.</span>
                    </li>
                </ul>
            </section>

            <section id="publications">
                <h1>ğŸ“ Selected Publications</h1>
                <p style="margin-bottom: 20px;">Full list available on <a href="https://scholar.google.com/citations?user=6AdA-O4AAAAJ&hl=zh-CN">Google Scholar</a>.</p>

                <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">ACM MM 2025</span>
                        <img src="images/stitchfusion.png" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="#" class="paper-title">Stitchfusion: Weaving any visual modalities to enhance multimodal semantic segmentation</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/StitchFusion">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/StitchFusion?style=social" alt="GitHub stars" />
                            <a href="https://arxiv.org/pdf/2408.01343">[Paper]</a>
                        </div>
                        <div class="paper-desc">We propose a novel framework to weave any visual modalities to enhance multimodal semantic segmentation.</div>
                    </div>
                </div>



                <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">AAAI 2026</span>
                        <img src="images/rskt.png" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="https://arxiv.org/pdf/2509.12040" class="paper-title">Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, H Dong, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/RSKT-Seg">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/RSKT-Seg?style=social" alt="GitHub stars" />
                            <a href="https://arxiv.org/pdf/2509.12040">[Paper]</a>
                        </div>
                        <div class="paper-desc">We explore efficient open-vocabulary segmentation methods tailored for remote sensing imagery.</div>
                    </div>
                </div>


                <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">arXiv 2025</span>
                        <img src="images/maris.png" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="https://arxiv.org/abs/2510.15398" class="paper-title">MARIS: Marine Open-Vocabulary Instance Segmentation</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, F Wang, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/MARIS">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/MARIS?style=social" alt="GitHub stars" />
                            <a href="https://arxiv.org/abs/2510.15398">[Paper]</a>
                        </div>
                        <div class="paper-desc">This work introduces MARIS for open-vocabulary instance segmentation in marine environments.</div>
                    </div>
                </div>


                <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">arXiv 2025</span>
                        <img src="images/earth2ocean.png" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="https://arxiv.org/pdf/2511.07923" class="paper-title">Exploring the Underwater World Segmentation without Extra Training</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, T Huo, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/Earth2Ocean">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/Earth2Ocean?style=social" alt="GitHub stars" />
                            <a href="https://arxiv.org/pdf/2511.07923">[Paper]</a>
                        </div>
                        <div class="paper-desc">We explore training-free segmentation methods for underwater scenes.</div>
                    </div>
                </div>


               <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">arXiv 2025</span>
                        <img src="images/fgaseg" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="https://arxiv.org/abs/2501.00877" class="paper-title">FGAseg: Fine-Grained Pixel-Text Alignment for Open-Vocabulary Semantic Segmentation</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/FGA-seg">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/FGA-seg?style=social" alt="GitHub stars" />
                            <a href="https://arxiv.org/abs/2501.00877">[Paper]</a>
                        </div>
                        <div class="paper-desc">We devise a fine-grained pixel-text alignment method for Open-Vocabulary Segmentation.</div>
                    </div>
               </div>

                <div class="paper-box">
                    <div class="paper-img">
                        <span class="badge">Pattern Recognition 2025</span>
                        <img src="images/u3m.png" alt="Paper Image" onerror="this.src='https://placehold.co/300x180?text=Paper+Image'">
                    </div>
                    <div class="paper-txt">
                        <a href="https://arxiv.org/abs/2501.00877" class="paper-title">FGAseg: Fine-Grained Pixel-Text Alignment for Open-Vocabulary Semantic Segmentation</a>
                        <div class="paper-authors"><strong>Bingyu Li</strong>, D Zhang, Z Zhao, J Gao, X Li</div>
                        <div>
                            <a href="https://github.com/LiBingyu01/U3M">[Code]</a> 
                            <img src="https://img.shields.io/github/stars/LiBingyu01/U3M?style=social" alt="GitHub stars" />
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325004613">[Paper]</a>
                        </div>
                        <div class="paper-desc">We devise a multi-scale and unbiased multimodal visual fusion method for multimodal segmentation.</div>
                    </div>
               </div>
                
            </section>


       <section id="honors">
        <h1 id="-honors-and-awards">ğŸ– Honors and Awards</h1>
          <ul>
            <li>2025, National Scholarship for Graduate Students | ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘</li>
          </ul>
       </section>   

    <section id="service">
        <h1 id="-academic-service">ğŸ”— Academic Service</h1>
          <p><strong>Reviewer</strong></p>
          <ul>
            <li><strong>Journal:</strong> TGRS, PR, etc.</li>
            <li><strong>Conference:</strong> CVPR, NeurIPS, ICLR, etc.</li>
          </ul>
    </section>  
  
        </main>
    </div>

</body>
</html>






